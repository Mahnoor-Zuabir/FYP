{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58d9c170",
   "metadata": {},
   "source": [
    "# MAJOR CODE I AM WORKING ON ONLY VISUALIZATION LEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8dcdd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mahnoor/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-3-25 Python-3.11.4 torch-2.2.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting real-time video stream\n",
      "Video saved to database and deleted from the computer successfully.\n",
      "the vdeo name is : 2024-11-24_01-54-46\n",
      "Stopping video stream\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "from PyQt5 import QtWidgets, QtGui, QtCore\n",
    "import sys\n",
    "import cv2\n",
    "from PyQt5.QtCore import QTimer\n",
    "from PyQt5.QtGui import QImage, QPixmap\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout,QHBoxLayout, QPushButton, QMessageBox, QLineEdit,QComboBox, QListWidget\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from PyQt5.QtCore import Qt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas\n",
    "import subprocess  # Add this line to import the subprocess module\n",
    "\n",
    "\n",
    "\n",
    "def get_geolocation(ip_address):\n",
    "    url = f\"http://ip-api.com/json/{ip_address}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    if data[\"status\"] == \"success\":\n",
    "        # Return latitude and longitude as floats\n",
    "        return float(data['lat']), float(data['lon'])\n",
    "    else:\n",
    "        print(\"Could not retrieve geolocation information.\")\n",
    "        return None, None  # Return None values if there's an error\n",
    "\n",
    "\n",
    "\n",
    "# Database connection\n",
    "def connect_db():\n",
    "    return mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"\",  # Replace with your password\n",
    "        database=\"viz_optilytics\"  # Replace with your database name\n",
    "    )\n",
    "######################################################################################\n",
    "# Load color reference CSV and create color lookup\n",
    "index = [\"color\", \"color_name\", \"hex\", \"R\", \"G\", \"B\"]\n",
    "csv = pd.read_csv('colors.csv', names=index, header=None)\n",
    "\n",
    "def get_color_name(bgr):\n",
    "    b, g, r = bgr\n",
    "    minimum = 10000\n",
    "    cname = \"Unknown\"\n",
    "    for i in range(len(csv)):\n",
    "        d = abs(r - int(csv.loc[i, \"R\"])) + abs(g - int(csv.loc[i, \"G\"])) + abs(b - int(csv.loc[i, \"B\"]))\n",
    "        if d <= minimum:\n",
    "            minimum = d\n",
    "            cname = csv.loc[i, \"color_name\"]\n",
    "    return cname\n",
    "\n",
    "# Function to extract color from bounding box\n",
    "def extract_color(frame, bbox):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    average_color = np.mean(roi, axis=(0, 1))\n",
    "    color_name = get_color_name(average_color)\n",
    "    return color_name\n",
    "###############################################  \n",
    "\n",
    "def save_vehicle_data(color, vehicle_type, timestamp, loc_lat, loc_lon):\n",
    "    try:\n",
    "        conn = connect_db()\n",
    "        cursor = conn.cursor()\n",
    "        print(\"I am savng the data to database\")\n",
    "        query = \"INSERT INTO vehicles (color, vehicle_type, timestamp, loc_lat, loc_lon) VALUES (%s,%s,%s,%s,%s)\"\n",
    "        cursor.execute(query, (color, vehicle_type, timestamp, loc_lat,loc_lon))\n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "        print(\"The data has been saved successfully\")\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error: {err}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        \n",
    "\n",
    "def save_people_data(people_count, timestamp, loc_lat, loc_lon):\n",
    "    try:\n",
    "        conn = connect_db()\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        query = \"INSERT INTO people (people_count, timestamp, loc_lat, loc_lon) VALUES (%s,%s,%s,%s)\"\n",
    "        cursor.execute(query, (people_count, timestamp, loc_lat,loc_lon))\n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error: {err}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        \n",
    "# Save video to database with name\n",
    "def save_video_to_db(video_path, video_name, start_time, duration, end_time):\n",
    "    try:\n",
    "        conn = connect_db()\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Read video file data\n",
    "        with open(video_path, 'rb') as f:\n",
    "            video_data = f.read()\n",
    "\n",
    "        # Insert video data into database\n",
    "        query = \"\"\"\n",
    "            INSERT INTO video_storage (video_name, video_file, start_time, duration, end_time)\n",
    "            VALUES (%s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        cursor.execute(query, (video_name, video_data, start_time, duration, end_time))\n",
    "        \n",
    "        # Commit transaction\n",
    "        conn.commit()\n",
    "        # Clean up\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "        # Optionally remove the file from the system\n",
    "        os.remove(video_path)\n",
    "        print(\"Video saved to database and deleted from the computer successfully.\")\n",
    "\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Database error: {err}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: The video file was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "class VizOptilyticsApp(QtWidgets.QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.setWindowTitle(\"Viz Optilytics\")\n",
    "        self.setGeometry(0, 0, 1200, 700)\n",
    "\n",
    "        # Initialize QTimer (fixing the timer error)\n",
    "        self.timer = QTimer(self)  # Initialize the QTimer object\n",
    "\n",
    "        # Initialize video capture object\n",
    "        self.video_capture = None\n",
    "\n",
    "        # Detection states\n",
    "        self.detecting_person = False\n",
    "        self.detecting_vehicle = False\n",
    "\n",
    "         # Track detected persons and duration\n",
    "        self.person_detected_time = None  # To track when a person is first detected\n",
    "        self.alert_generated = False  # To track if alert is already generated\n",
    "        \n",
    "        # Load YOLOv5 model\n",
    "        self.model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # Load YOLOv5 model\n",
    "\n",
    "         # Initialize alert labels for dynamic updates\n",
    "        self.alert_label = None\n",
    "        self.duration_label = None\n",
    "        \n",
    "        self.detection_grace_period = 10  # Number of frames to maintain detection box\n",
    "        self.frames_since_last_detection = 0\n",
    "        self.last_detection_box = None  # Store the last detected bounding box\n",
    "\n",
    "        \n",
    "        self.vehicle_positions = {}  # Stores vehicle ID -> (last position, detection start time)\n",
    "        self.stationary_alert_generated = {}  # To track if stationary alert has been generated\n",
    "\n",
    "        self.video1 = False\n",
    "        self.video2 = False\n",
    "        self.video3 = False\n",
    "        self.real_time_stream = False\n",
    "        self.record_flag = False\n",
    "\n",
    "        self.person_count = 0  # Track number of people detected\n",
    "        \n",
    "        self.initUI()\n",
    "    def initUI(self):\n",
    "        # Main Layout\n",
    "        main_layout = QtWidgets.QVBoxLayout(self)\n",
    "        main_layout.setContentsMargins(50, 50, 50, 30)\n",
    "\n",
    "        # Top Section: Title and Menu\n",
    "        top_bar = QtWidgets.QHBoxLayout()\n",
    "#         top_bar.addStretch(1)\n",
    "\n",
    "        title = QtWidgets.QLabel(\"Viz Optilytics\")\n",
    "        title.setFont(QtGui.QFont(\"Arial\", 28, QtGui.QFont.Bold))\n",
    "        title.setStyleSheet(\"color: #FFD700;\")\n",
    "        title.setAlignment(QtCore.Qt.AlignLeft)\n",
    "\n",
    "        top_bar.addWidget(title)\n",
    "        top_bar.addStretch(2)\n",
    "\n",
    "        top_bar.addStretch(1)\n",
    "        \n",
    "        menu_button = QtWidgets.QPushButton(\"Recordings\")\n",
    "        menu_button.setStyleSheet(\"background-color: #333333; color: #FFD700; font-size: 20px; border-radius: 10px;\")\n",
    "        menu_button.setFixedSize(50, 50)\n",
    "        menu_button.clicked.connect(self.show_recordings)\n",
    "\n",
    "        top_bar.addWidget(menu_button)\n",
    "        main_layout.addLayout(top_bar)\n",
    "\n",
    "        title_spacer = QtWidgets.QSpacerItem(20, 40, QtWidgets.QSizePolicy.Minimum, QtWidgets.QSizePolicy.Fixed)\n",
    "        main_layout.addItem(title_spacer)\n",
    "\n",
    "        # Horizontal layout split: Videos, Buttons, Alerts, etc.\n",
    "        content_layout = QtWidgets.QHBoxLayout()\n",
    "        content_layout.setSpacing(20)\n",
    "\n",
    "        # Video Buttons and Info Section\n",
    "        main_vertical_layout = QtWidgets.QVBoxLayout()\n",
    "\n",
    "        video_list_layout = QtWidgets.QVBoxLayout()\n",
    "        recorded_videos_label = QtWidgets.QLabel(\"Recorded Videos\")\n",
    "        recorded_videos_label.setFont(QtGui.QFont(\"Arial\", 16, QtGui.QFont.Bold))\n",
    "        recorded_videos_label.setStyleSheet(\"color: white;\")\n",
    "        video_list_layout.addWidget(recorded_videos_label)\n",
    "\n",
    "        # Video buttons\n",
    "        for i in range(3):\n",
    "            video_btn = QtWidgets.QPushButton(f\"Video {i + 1}\")\n",
    "            video_btn.setStyleSheet(\"background-color: #555555; color: white; border-radius: 8px; padding: 8px;\")\n",
    "            video_btn.setFixedWidth(200)\n",
    "            video_btn.setSizePolicy(QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Fixed)\n",
    "\n",
    "            # Connect each button to a separate function based on the index\n",
    "            if i == 0:\n",
    "                video_btn.clicked.connect(self.play_video_1)\n",
    "            elif i == 1:\n",
    "                video_btn.clicked.connect(self.play_video_2)\n",
    "            elif i == 2:\n",
    "                video_btn.clicked.connect(self.play_video_3)\n",
    "\n",
    "            video_list_layout.addWidget(video_btn)\n",
    "\n",
    "        main_vertical_layout.addLayout(video_list_layout)\n",
    "\n",
    "        detection_info_widget = QtWidgets.QWidget()\n",
    "        detection_info_layout = QtWidgets.QVBoxLayout(detection_info_widget)\n",
    "        detection_info_layout.setSpacing(0)\n",
    "        detection_info_widget.setStyleSheet(\"background-color: #444444; border-radius: 10px;\")\n",
    "\n",
    "        current_date = time.strftime(\"%Y-%m-%d\", time.localtime())\n",
    "        date_label = QtWidgets.QLabel(f\"Current Date: {current_date}\")\n",
    "        date_label.setStyleSheet(\"color: white; font-size: 14px; padding: 8px;\")\n",
    "        detection_info_layout.addWidget(date_label)  # Add date label\n",
    "\n",
    "        # Current time label\n",
    "        current_time = time.strftime(\"%H:%M:%S\", time.localtime())\n",
    "        time_label = QtWidgets.QLabel(f\"Current Time: {current_time}\")\n",
    "        time_label.setStyleSheet(\"color: white; font-size: 14px; padding: 8px;\")\n",
    "        detection_info_layout.addWidget(time_label)  # Add time label\n",
    "\n",
    "        self.detection_status = QtWidgets.QLabel(\"Status: Vehicle Detected\")\n",
    "        self.detection_status.setStyleSheet(\"color: white; font-size: 14px; padding: 8px;\")\n",
    "        detection_info_layout.addWidget(self.detection_status)\n",
    "        main_vertical_layout.addWidget(detection_info_widget)\n",
    "\n",
    "        # Real-time streaming button\n",
    "        real_time_btn = QtWidgets.QPushButton(\"Real-Time Streaming\")\n",
    "        real_time_btn.setStyleSheet(\"background-color: #666666; padding: 10px; font-size: 14px; border-radius: 8px;\")\n",
    "        real_time_btn.setFixedWidth(200)\n",
    "        real_time_btn.setSizePolicy(QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Fixed)\n",
    "        real_time_btn.clicked.connect(self.start_real_time_stream)\n",
    "        main_vertical_layout.addWidget(real_time_btn)\n",
    "\n",
    "        # Analytics button\n",
    "        analytics_btn = QtWidgets.QPushButton(\"Analytics\")\n",
    "        analytics_btn.setStyleSheet(\"background-color: #666666; padding: 10px; font-size: 14px; border-radius: 8px;\")\n",
    "        analytics_btn.setFixedWidth(200)\n",
    "        analytics_btn.setSizePolicy(QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Fixed)\n",
    "        analytics_btn.clicked.connect(self.show_analytics)\n",
    "        main_vertical_layout.addWidget(analytics_btn)\n",
    "\n",
    "        content_layout.addLayout(main_vertical_layout)\n",
    "\n",
    "        # Video display area and other buttons\n",
    "        main_left_layout = QtWidgets.QVBoxLayout()\n",
    "\n",
    "        video_layout = QtWidgets.QVBoxLayout()\n",
    "        video_controls_layout = QtWidgets.QHBoxLayout()\n",
    "\n",
    "        # Create a layout to position the close button at the top-right corner\n",
    "        close_button = QtWidgets.QPushButton(\"X\")\n",
    "        close_button.setStyleSheet(\"background-color: red; color: white; font-size: 18px; border-radius: 10px;\")\n",
    "        close_button.setFixedSize(30, 30)\n",
    "        close_button.clicked.connect(self.stop_stream)\n",
    "\n",
    "        # Create a wrapper for the video feed and the button\n",
    "        video_feed_wrapper = QtWidgets.QWidget()\n",
    "        video_feed_layout = QtWidgets.QVBoxLayout(video_feed_wrapper)\n",
    "        video_feed_wrapper.setFixedSize(970, 420)\n",
    "        video_feed_layout.setContentsMargins(0, 0, 0, 0)  # Remove margins for precise alignment\n",
    "\n",
    "        # Create a layout for the close button at the top-right corner\n",
    "        close_button_layout = QtWidgets.QHBoxLayout()\n",
    "        close_button_layout.addStretch(1)  # Add stretch to push the button to the right\n",
    "        close_button_layout.addWidget(close_button)\n",
    "\n",
    "        video_feed_layout.addLayout(close_button_layout)  # Add the close button layout\n",
    "        self.video_feed = QtWidgets.QLabel(\"Video Stream\")\n",
    "        self.video_feed.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        self.video_feed.setStyleSheet(\"background-color: white; color: black; border: 2px solid;\")\n",
    "        self.video_feed.setFixedSize(970, 480)  # Set a fixed size for the video feed\n",
    "        self.video_feed.setScaledContents(True)\n",
    "        self.video_feed.setSizePolicy(QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Expanding)\n",
    "\n",
    "        video_feed_layout.addWidget(self.video_feed)  # Add the video feed below the button\n",
    "\n",
    "        # Add the video feed wrapper to the main video layout\n",
    "        video_layout.addWidget(video_feed_wrapper)\n",
    "\n",
    "        # Detection buttons\n",
    "        detection_buttons_layout = QtWidgets.QHBoxLayout()\n",
    "        self.record_btn = QtWidgets.QPushButton(\"Start Record\")\n",
    "        self.record_btn.setStyleSheet(\"background-color: #666666; color: white; padding: 10px; font-size: 14px; border-radius: 8px;\")\n",
    "        self.record_btn.setSizePolicy(QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Fixed)\n",
    "        self.record_btn.clicked.connect(self.toggle_record)\n",
    "        detection_buttons_layout.addWidget(self.record_btn)\n",
    "\n",
    "       # Assigning person_detection_btn as an instance variable\n",
    "        self.person_detection_btn = QtWidgets.QPushButton(\"Person Detection\")\n",
    "        self.person_detection_btn.setStyleSheet(\"background-color: #666666; color: white; padding: 10px; font-size: 14px; border-radius: 8px;\")\n",
    "        self.person_detection_btn.setSizePolicy(QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Fixed)\n",
    "        self.person_detection_btn.clicked.connect(self.toggle_person_detection)\n",
    "        detection_buttons_layout.addWidget(self.person_detection_btn)\n",
    "\n",
    "        self.vehicle_detection_btn = QtWidgets.QPushButton(\"Vehicle Detection\")\n",
    "        self.vehicle_detection_btn.setStyleSheet(\"background-color: #666666; color: white; padding: 10px; font-size: 14px; border-radius: 8px;\")\n",
    "        self.vehicle_detection_btn.setSizePolicy(QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Fixed)\n",
    "        self.vehicle_detection_btn.clicked.connect(self.toggle_vehicle_detection)\n",
    "        detection_buttons_layout.addWidget(self.vehicle_detection_btn)\n",
    "\n",
    "        video_layout.addLayout(detection_buttons_layout)\n",
    "        main_left_layout.addLayout(video_layout)\n",
    "\n",
    "        # Alerts section\n",
    "        alerts_layout = QtWidgets.QHBoxLayout()\n",
    "        self.alert_label = QtWidgets.QLabel(\"Alert: No Detection\")\n",
    "        self.alert_label.setFixedSize(450, 37)  # Set fixed size for the alert label\n",
    "        self.alert_label.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        self.alert_label.setStyleSheet(\"background-color: green; color: white; padding: 10px; font-size: 14px; border-radius: 8px;\")\n",
    "        alerts_layout.addWidget(self.alert_label)\n",
    "\n",
    "        self.duration_label = QtWidgets.QLabel(\"Time Duration: 00:00:00\")\n",
    "        self.duration_label.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        self.duration_label.setFixedSize(450, 37)  # Set fixed size for the alert label\n",
    "        self.duration_label.setStyleSheet(\"background-color: green; color: white; padding: 10px; font-size: 14px; border-radius: 8px;\")\n",
    "        alerts_layout.addWidget(self.duration_label)\n",
    "\n",
    "        main_left_layout.addLayout(alerts_layout)\n",
    "        content_layout.addLayout(main_left_layout)\n",
    "\n",
    "        main_layout.addLayout(content_layout)\n",
    "        self.setStyleSheet(\"background-color: #222222; color: white;\")\n",
    "\n",
    "        self.setLayout(main_layout)\n",
    "        \n",
    "    \n",
    "    def toggle_record(self):\n",
    "        if not self.record_flag:\n",
    "            self.record_flag = True\n",
    "            self.record_btn.setText(\"Stop Record\")\n",
    "            self.record_options()\n",
    "        else:\n",
    "            self.record_flag = False\n",
    "            self.record_btn.setText(\"Start Record\")\n",
    "\n",
    "    def record_options(self):\n",
    "        msg_box = QMessageBox()\n",
    "        msg_box.setWindowTitle(\"Choose Recording Type\")\n",
    "        msg_box.setText(\"Do you want to record the full video or use optimal storage?\")\n",
    "        full_button = msg_box.addButton(\"Full Video\", QMessageBox.YesRole)\n",
    "        optimal_button = msg_box.addButton(\"Optimal Storage\", QMessageBox.NoRole)\n",
    "        msg_box.exec_()\n",
    "        \n",
    "        if msg_box.clickedButton() == full_button:\n",
    "            self.record_and_save_video(optimal=False)\n",
    "        elif msg_box.clickedButton() == optimal_button:\n",
    "            self.record_and_save_video(optimal=True)\n",
    "\n",
    "    def record_and_save_video(self, optimal):\n",
    "        now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        output_file = f\"{now}.avi\"\n",
    "        self.video_display(output_file, optimal)  # Start the video display and recording\n",
    "\n",
    "        # Notify the user that the recording has started\n",
    "        QMessageBox.information(self, \"Recording Started\", \"Video recording in progress...\")\n",
    "        # Store the start time\n",
    "        self.start_time = datetime.now()\n",
    "        # Connect the timer to check recording status\n",
    "        self.timer.timeout.connect(lambda: self.check_recording_status(output_file, now, self.start_time))\n",
    "\n",
    "    def check_recording_status(self, output_file, video_name, start_time):\n",
    "        if not self.record_flag:  # Check if recording is complete\n",
    "            self.timer.stop()  # Stop the timer\n",
    "            # Calculate the end time and duration\n",
    "            end_time = datetime.now()\n",
    "            duration = end_time - start_time  # Calculate duration as a timedelta\n",
    "            # Release the video writer if it's active\n",
    "            if hasattr(self, 'out') and self.out is not None:\n",
    "                self.out.release()\n",
    "            # Format times for display or database storage\n",
    "            start_time_str = start_time.strftime(\"%H:%M:%S\")\n",
    "            end_time_str = end_time.strftime(\"%H:%M:%S\")\n",
    "            duration_seconds = int(duration.total_seconds())\n",
    "            duration_hours, remainder = divmod(duration_seconds, 3600)\n",
    "            duration_minutes, duration_seconds = divmod(remainder, 60)\n",
    "            duration_str = f\"{duration_hours:02}:{duration_minutes:02}:{duration_seconds:02}\"\n",
    "\n",
    "            # Save the video to the database with details\n",
    "            save_video_to_db(output_file, video_name, start_time_str, duration_str, end_time_str)\n",
    "            print(f\"the vdeo name is : {video_name}\")\n",
    "            # Notify the user that recording is complete\n",
    "            QMessageBox.information(self, \"Recording Complete\", \"Video recorded and saved to database successfully.\")\n",
    "            self.video_display()\n",
    "            \n",
    "    def video_display(self, output_path=None, optimal=False):\n",
    "#         self.optimal = optimal\n",
    "        if self.real_time_stream:\n",
    "            self.video_capture = cv2.VideoCapture(0)\n",
    "        elif self.video1:\n",
    "            self.video_capture = cv2.VideoCapture(r\"C:\\Users\\mahnoor\\Downloads\\853889-hd_1920_1080_25fps.mp4\")\n",
    "        elif self.video2:\n",
    "            self.video_capture = cv2.VideoCapture(r\"C:\\Users\\mahnoor\\Downloads\\2273134-hd_1280_720_30fps.mp4\")\n",
    "        elif self.video3:\n",
    "            self.video_capture = cv2.VideoCapture(r\"C:\\Users\\mahnoor\\Downloads\\12494476_3840_2160_50fps.mp4\")\n",
    "        if self.record_flag:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "            self.out = cv2.VideoWriter(output_path, fourcc, 20.0, (640, 480))\n",
    "        ret, prev_frame = self.video_capture.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to access the camera\")\n",
    "            return\n",
    "        if self.record_flag:\n",
    "            self.prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY) if optimal else None\n",
    "        # Disconnect previous connections to avoid duplicates\n",
    "        try:\n",
    "            self.timer.timeout.disconnect()\n",
    "        except TypeError:\n",
    "            # No existing connection to disconnect\n",
    "            pass\n",
    "        # Connect the update_frame method properly without calling it immediately\n",
    "        self.timer.timeout.connect(lambda: self.update_frame(optimal))\n",
    "        self.timer.start(20)\n",
    "    \n",
    "    def update_frame(self, optimal=False):\n",
    "        ret, frame = self.video_capture.read()\n",
    "        if ret:\n",
    "            if self.record_flag and hasattr(self, 'out') and self.out is not None:\n",
    "                if optimal:\n",
    "                    # Convert current frame to grayscale for comparison\n",
    "                    curr_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                    # Compute the absolute difference between current and previous frames\n",
    "                    diff = cv2.absdiff(self.prev_gray, curr_gray)\n",
    "                    _, thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)\n",
    "                    non_zero_count = cv2.countNonZero(thresh)\n",
    "\n",
    "                    # Save the frame only if there is significant change\n",
    "                    if non_zero_count > 10000:\n",
    "                        self.out.write(frame)\n",
    "                        self.prev_gray = curr_gray  # Update the previous frame\n",
    "                else:\n",
    "                    # Full video recording, save every frame\n",
    "                    self.out.write(frame)\n",
    "\n",
    "            # Convert the frame to RGB for display\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            if self.detecting_person:\n",
    "                frame = self.detect_person(frame)\n",
    "            if self.detecting_vehicle:\n",
    "                frame = self.detect_vehicle(frame)\n",
    "\n",
    "            # Get the frame dimensions and convert to QImage\n",
    "            h, w, ch = frame.shape\n",
    "            bytes_per_line = ch * w\n",
    "            qimg = QImage(frame.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "\n",
    "            self.video_feed.setPixmap(QPixmap.fromImage(qimg))\n",
    "        else:\n",
    "            print(\"Error: Unable to read video frame\")\n",
    "\n",
    "    def stop_stream(self):\n",
    "        print(\"Stopping video stream\")\n",
    "        if self.video_capture is not None:\n",
    "            self.video_capture.release()\n",
    "#             self.out.release()\n",
    "            self.video_capture = None\n",
    "            self.video_feed.clear()\n",
    "            self.timer.stop()\n",
    "\n",
    "    def toggle_person_detection(self):\n",
    "        \"\"\"Toggle person detection on or off.\"\"\"\n",
    "        self.detecting_person = not self.detecting_person  # Toggle detection state\n",
    "\n",
    "        if self.detecting_person:\n",
    "            self.person_detection_btn.setText(\"Stop Person Detection\")\n",
    "        else:\n",
    "            self.person_detection_btn.setText(\"Start Person Detection\")\n",
    "\n",
    "            # Reset detection states when stopping\n",
    "            self.person_detected_time = None\n",
    "            self.alert_generated = False\n",
    "            self.alert_label.setText(\"Alert: No Detection\")\n",
    "            self.alert_label.setStyleSheet(\"background-color: green; color: white;\")\n",
    "            self.duration_label.setText(\"Time Duration: 00:00:00\")\n",
    "            self.duration_label.setStyleSheet(\"background-color: green; color: white;\")\n",
    "\n",
    "\n",
    "    def detect_person(self, frame):\n",
    "        # Perform inference\n",
    "        results = self.model(frame)\n",
    "        predictions = results.pred[0]\n",
    "\n",
    "        person_count = 0\n",
    "        for *box, conf, cls in predictions:\n",
    "            if int(cls) == 0:  # Class index for person\n",
    "                person_count += 1\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Draw bounding box\n",
    "                cv2.putText(frame, f'Person', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Update the number of people detected in the frame\n",
    "        self.person_count = person_count\n",
    "\n",
    "        # Check if person count exceeds 2\n",
    "        if person_count > 2:\n",
    "            self.update_person_detection_time()\n",
    "        else:\n",
    "            self.reset_person_detection()\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def update_person_detection_time(self):\n",
    "        \"\"\"Track how long multiple people have been in the frame and update alert if needed.\"\"\"\n",
    "        if self.person_detected_time is None:\n",
    "            self.person_detected_time = time.time()  # Start the timer\n",
    "\n",
    "        duration = time.time() - self.person_detected_time\n",
    "\n",
    "        # Format the duration\n",
    "        hours, rem = divmod(duration, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        duration_str = \"{:02}:{:02}:{:02}\".format(int(hours), int(minutes), int(seconds))\n",
    "\n",
    "        # Update duration label\n",
    "        self.duration_label.setText(f\"Time Duration: {duration_str}\")\n",
    "\n",
    "        # Check if detection duration exceeds the threshold (5 minutes or 300 seconds)\n",
    "        if duration > 5 and not self.alert_generated:\n",
    "            self.alert_label.setText(\"ALERT: More than 2 people detected for over 5 seconds!\")\n",
    "            self.alert_label.setStyleSheet(\"background-color: red; color: white;\")\n",
    "            self.duration_label.setStyleSheet(\"background-color: red; color: white;\")\n",
    "            self.alert_generated = True\n",
    "            self.detection_status.setText(f\"Status : {self.person_count} : people detected\")\n",
    "\n",
    "            # Print head count and formatted time\n",
    "            formatted_time = datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(f\"The number of head count is {self.person_count}\")\n",
    "            print(f\"The time of detection is {formatted_time}\")\n",
    "            loc_lat, loc_lon = get_geolocation(\"182.183.56.95\")\n",
    "            save_people_data(self.person_count, formatted_time, loc_lat, loc_lon)\n",
    "            \n",
    "    def reset_person_detection(self):\n",
    "        \"\"\"Reset the detection state if fewer than three people are found.\"\"\"\n",
    "        if self.person_detected_time is not None:\n",
    "            self.person_detected_time = None  # Reset the timer\n",
    "            self.duration_label.setText(\"Time Duration: 00:00:00\")\n",
    "            self.alert_label.setText(\"Alert: No Detection\")\n",
    "            self.alert_label.setStyleSheet(\"background-color: green; color: white;\")\n",
    "            self.duration_label.setStyleSheet(\"background-color: green; color: white;\")\n",
    "            self.alert_generated = False\n",
    "            self.person_count = 0  # Reset the person count to zero\n",
    "\n",
    "\n",
    "            \n",
    "    def detect_vehicle(self, frame):\n",
    "        # Perform inference using YOLOv5 model\n",
    "        results = self.model(frame)\n",
    "\n",
    "        # Get predictions\n",
    "        predictions = results.pred[0]\n",
    "\n",
    "        current_time = time.time()  # Get the current time\n",
    "        vehicle_detected = False  # Flag to check if any vehicle is detected\n",
    "\n",
    "        # Dictionary to map class ids to vehicle types\n",
    "        vehicle_class_map = {\n",
    "            2: \"Car\",        # Car\n",
    "            3: \"Motorcycle\", # Motorcycle\n",
    "            5: \"Bus\",       # Bus\n",
    "            7: \"Truck\"      # Truck\n",
    "        }\n",
    "\n",
    "        for *box, conf, cls in predictions:\n",
    "            cls = int(cls)  # Convert cls to an integer for checking\n",
    "            box = list(map(int, box))  # Ensure box contains integers\n",
    "#             print(f\"Bounding Box: {box}, Type: {type(box)}\")  # Debugging statement\n",
    "\n",
    "            if cls in vehicle_class_map:  # Only process valid vehicle classes\n",
    "                vehicle_type = vehicle_class_map[cls]\n",
    "                x1, y1, x2, y2 = box  # Unpacking the corrected box\n",
    "                \n",
    "                # Calculate the center of the bounding box\n",
    "                vehicle_center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "                vehicle_detected = True  # Set the flag to True since we detected a vehicle\n",
    "\n",
    "                # Use the center position to track vehicle movement\n",
    "                if vehicle_type not in self.vehicle_positions:\n",
    "                    # If this is a new vehicle, start tracking it\n",
    "                    self.vehicle_positions[vehicle_type] = (vehicle_center, current_time)\n",
    "                    self.stationary_alert_generated[vehicle_type] = False\n",
    "                else:\n",
    "                    # Get the previous position and detection start time\n",
    "                    prev_position, start_time = self.vehicle_positions[vehicle_type]\n",
    "\n",
    "                    # Calculate movement distance between current and previous position\n",
    "                    movement_distance = np.linalg.norm(np.array(vehicle_center) - np.array(prev_position))\n",
    "\n",
    "                    # Define a movement threshold (e.g., 20 pixels)\n",
    "                    movement_threshold = 20\n",
    "\n",
    "                    if movement_distance < movement_threshold:\n",
    "                        # If the vehicle has not moved significantly, check how long it's been stationary\n",
    "                        stationary_duration = current_time - start_time\n",
    "\n",
    "                        # Update the time duration label\n",
    "                        self.duration_label.setText(f\"Vehicle {vehicle_type} stationary for {int(stationary_duration)} seconds\")\n",
    "\n",
    "                        # Check if the stationary duration exceeds 5 minutes (300 seconds)\n",
    "                        if stationary_duration > 5 and not self.stationary_alert_generated[vehicle_type]:\n",
    "                            self.alert_label.setText(f\"ALERT: {vehicle_type} stationary for over 5 minutes!\")\n",
    "                            self.alert_label.setStyleSheet(\"background-color: red; color: white;\")\n",
    "                            self.duration_label.setStyleSheet(\"background-color: red; color: white;\")\n",
    "                            self.stationary_alert_generated[vehicle_type] = True  # Mark that the alert has been generated\n",
    "                            self.detection_status.setText(f\"Status : {vehicle_type} detected\")\n",
    "                            color = extract_color(frame, box)  # Corrected bounding box variable\n",
    "                            timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "                            loc_lat, loc_lon = get_geolocation(\"182.183.56.95\")  # Consider making IP dynamic\n",
    "                            print(\"Saving the data in database\")\n",
    "                            print(f\"color: {color}/n type: {vehicle_type} /n timestamp : {timestamp} lat_lon : {loc_lat} _ {loc_lon}\")\n",
    "                            save_vehicle_data(color, vehicle_type, timestamp, loc_lat, loc_lon)\n",
    "                    else:\n",
    "                        # If the vehicle moved, reset the detection start time\n",
    "                        self.vehicle_positions[vehicle_type] = (vehicle_center, current_time)\n",
    "                        self.stationary_alert_generated[vehicle_type] = False\n",
    "\n",
    "                # Draw the bounding box and label the vehicle\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f'{vehicle_type}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "        # If no vehicle is detected, reset the alert and duration labels\n",
    "        if not vehicle_detected:\n",
    "            self.alert_label.setText(\"No vehicle detected\")\n",
    "            self.alert_label.setStyleSheet(\"background-color: green; color: white;\")\n",
    "            self.duration_label.setText(\"No detection duration: 00 seconds\")\n",
    "            self.duration_label.setStyleSheet(\"background-color: green; color: white;\")\n",
    "        return frame\n",
    "    \n",
    "    \n",
    "    def toggle_vehicle_detection(self):\n",
    "        \"\"\"Toggle vehicle detection on and off.\"\"\"\n",
    "        self.detecting_vehicle = not self.detecting_vehicle  # Toggle the state\n",
    "        if self.detecting_vehicle:\n",
    "            self.vehicle_detection_btn.setText(\"Stop vehicle Detection\")\n",
    "        else:\n",
    "            self.vehicle_detection_btn.setText(\"Start vehicle Detection\")\n",
    "            self.alert_generated = False\n",
    "            self.alert_label.setText(\"Alert: No Detection\")\n",
    "            self.alert_label.setStyleSheet(\"background-color: green; color: white;\")\n",
    "            self.duration_label.setText(\"Time Duration: 00:00:00\")\n",
    "            self.duration_label.setStyleSheet(\"background-color: green; color: white;\")\n",
    "\n",
    "\n",
    "    def start_real_time_stream(self):\n",
    "        print(\"Starting real-time video stream\")\n",
    "        self.real_time_stream=True\n",
    "        # Start video capture (assuming you have a webcam at index 0)\n",
    "        self.video_display()  # Call video_feed to initiate video capture\n",
    "            \n",
    "   # Define the three separate play video functions\n",
    "    def play_video_1(self):\n",
    "        print(\"Playing Video 1\")\n",
    "        self.real_time_stream=False\n",
    "        self.video1 = True  # Set instance variable\n",
    "        self.video2 = False  # Reset other video flags\n",
    "        self.video3 = False\n",
    "        self.stop_stream()  # Stop any current stream before starting a video\n",
    "        self.video_display()  # Call video_feed to start playing the video\n",
    "\n",
    "    def play_video_2(self):\n",
    "        print(\"Playing Video 2\")\n",
    "        self.real_time_stream=False\n",
    "        self.video1 = False  # Reset other video flags\n",
    "        self.video2 = True\n",
    "        self.video3 = False\n",
    "        self.stop_stream()  # Stop any current stream before starting a video\n",
    "        self.video_display()  # Call video_feed to start playing the video\n",
    "\n",
    "    def play_video_3(self):\n",
    "        print(\"Playing Video 3\")\n",
    "        self.real_time_stream=False\n",
    "        self.video1 = False  # Reset other video flags\n",
    "        self.video2 = False\n",
    "        self.video3 = True\n",
    "        self.stop_stream()  # Stop any current stream before starting a video\n",
    "        self.video_display()  # Call video_feed to start playing the video\n",
    "\n",
    "    # Add your logic to play video 3 here\n",
    "    def show_analytics(self):\n",
    "        subprocess.run(['python', 'ANALYTICS.py'], check=True)  # Run the Python script        \n",
    "    \n",
    "    def show_recordings(self):\n",
    "        subprocess.run(['python', 'recording.py'], check=True)  # Run the Python script        \n",
    "        \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    window = VizOptilyticsApp()\n",
    "    window.show()\n",
    "    sys.exit(app.exec_())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
